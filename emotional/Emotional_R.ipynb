{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03f088ea",
   "metadata": {},
   "source": [
    "## 引入库文件并读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91907e80",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# install.packages(\"readr\")\n",
    "# install.packages(\"dplyr\")\n",
    "# install.packages(\"jiebaR\")\n",
    "library(dplyr)\n",
    "library(jiebaR)\n",
    "library(readr)\n",
    "library(parallel)\n",
    "library(stringr)\n",
    "# 读取 CSV 文件\n",
    "data <- read_csv('precessed.csv')\n",
    "# 查看数据框\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bd8221",
   "metadata": {},
   "source": [
    "## 函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f674f0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化 jiebaR 分词器\n",
    "cutter <- worker()\n",
    "\n",
    "# 标题文本处理\n",
    "process_title <- function(data) {\n",
    "  titles <- c()\n",
    "  print(paste(\"数据长度:\", length(data)))\n",
    "  it<-0\n",
    "  for (title in data) {\n",
    "    if (!is.na(title)&&is.character(title)) {\n",
    "      if (substr(title, 1, 4) == \"慈善募捐\") {\n",
    "        titles <- c(titles, substr(title, 8, nchar(title) - 7))\n",
    "      } else {\n",
    "        titles <- c(titles, title)\n",
    "      }\n",
    "    } else {\n",
    "      titles <- c(titles, title)\n",
    "    }\n",
    "    it <- it + 1  # 增加计数器\n",
    "    if (it %% 1000 == 0) {\n",
    "      print(paste(\"已处理:\", it, \"条记录\"))\n",
    "    }\n",
    "  }\n",
    "  return(titles)\n",
    "}\n",
    "\n",
    "# 项目介绍文本处理\n",
    "process_detail <- function(data) {\n",
    "  patterns <- c('（[^（）]*?图[^（）]*?）', '【[^【】]*?图[^【】]*?】', '（[^（）]*?照片[^（）]*?）', '【[^【】]*?照片[^【】]*?】')\n",
    "  photo <- c() # 照片数量\n",
    "  detail_ <- c() # 剔除这类信息后的文本\n",
    "  details <- c() # 最终返回的文本\n",
    "\n",
    "  for (detail in data) {\n",
    "    if (is.character(detail)) {\n",
    "      match <- c()\n",
    "      for (pattern in patterns) {\n",
    "        match <- c(match, str_extract_all(detail, pattern)[[1]])\n",
    "        detail <- str_replace_all(detail, pattern, \"\")\n",
    "      }\n",
    "      photo <- c(photo, length(match))\n",
    "      detail_ <- c(detail_, detail)\n",
    "    } else {\n",
    "      detail_ <- c(detail_, \"\")\n",
    "      photo <- c(photo, 0)\n",
    "    }\n",
    "  }\n",
    "\n",
    "  # 处理 detail_ 中的文本\n",
    "  for (detail in detail_) {\n",
    "    if (!is.na(detail) && detail != \"\") {\n",
    "      text <- str_replace_all(detail, \"', '\", \"\")\n",
    "      details <- c(details, text)\n",
    "    } else {\n",
    "      details <- c(details, detail)\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return(list(photo = photo, details = details))\n",
    "}\n",
    "\n",
    "\n",
    "# jieba分词，返回分出来的词，同时剔除非中文非数字字符；处理对象为文本\n",
    "# 清洗文本并进行分词\n",
    "clean <- function(text) {\n",
    "  # 去除非中文和非数字字符\n",
    "  pattern <- '[^\\u4e00-\\u9fa5\\\\d]'  # 匹配非中文字符和非数字字符\n",
    "  clean_words <- c()\n",
    "\n",
    "  if (is.character(text)) {\n",
    "    # 使用 jiebaR 的分词器进行中文分词\n",
    "    words <- segment(text, cutter)\n",
    "\n",
    "    # 对每个词进行处理\n",
    "    for (word in words) {\n",
    "      clean_word <- gsub(pattern, \"\", word)  # 去掉非中文和非数字字符\n",
    "      if (clean_word != \"\") {\n",
    "        clean_words <- c(clean_words, clean_word)  # 保存有效的词汇\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return(clean_words)\n",
    "}\n",
    "\n",
    "\n",
    "# # 信息量,计算clean后分词的数量\n",
    "get_info <- function(lst) {\n",
    "  info <- c()\n",
    "  for (item in lst) {\n",
    "    clean_words <- clean(item)\n",
    "    info <- c(info, length(clean_words))\n",
    "\n",
    "  }\n",
    "  return(info)\n",
    "}\n",
    "\n",
    "# 筛选强烈情感的符号\n",
    "get_mark <- function(data) {\n",
    "  Exclamation <- c()\n",
    "  QMark <- c()\n",
    "  for (text in data) {\n",
    "    words <- segment(text, cutter)\n",
    "    Exclamation <- c(Exclamation, sum(words == '？') + sum(words == '?'))\n",
    "    QMark <- c(QMark, sum(words == '！'))\n",
    "  }\n",
    "  return(list(Exclamation = Exclamation, QMark = QMark))\n",
    "}\n",
    "\n",
    "# 计算文档频率\n",
    "document_frequency <- function(list_of_text) {\n",
    "  # 初始化文档频率字典\n",
    "  document_frequency <- list()\n",
    "\n",
    "  # 遍历每个文本并更新文档频率字典\n",
    "  for (text in list_of_text) {\n",
    "    if (!is.na(text) && is.character(text)) {\n",
    "      words <- segment(text, cutter)\n",
    "      for (word in words) {\n",
    "        if (word %in% names(document_frequency)) {\n",
    "          document_frequency[[word]] <- document_frequency[[word]] + 1\n",
    "        } else {\n",
    "          document_frequency[[word]] <- 1\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return(document_frequency)\n",
    "}\n",
    "\n",
    "# 计算熵\n",
    "calculate_entropy <- function(text, list_of_text, document_frequency) {\n",
    "  # 需要先有 document_frequency，可以用上一个函数获取。\n",
    "  # 返回的是输入内容的熵\n",
    "  if (!is.na(text) && is.character(text)) {\n",
    "    words <- segment(text,cutter)\n",
    "    word_counts <- table(words)\n",
    "    total_words <- length(words)\n",
    "    entropy <- 0.0\n",
    "\n",
    "    for (word in names(word_counts)) {\n",
    "      count <- word_counts[[word]]\n",
    "      probability <- count / total_words\n",
    "      inverse_document_frequency <- log((length(list_of_text) + 1) / (document_frequency[[word]] + 1))\n",
    "      entropy <- entropy + inverse_document_frequency * probability * log(probability, 2)\n",
    "    }\n",
    "\n",
    "    entropy <- -entropy\n",
    "  } else {\n",
    "    entropy <- NA\n",
    "  }\n",
    "\n",
    "  return(entropy)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f954251",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d59c5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Title\n",
    "titles <- process_title(data$项目名称)\n",
    "data$TInfo <- get_info(titles)\n",
    "\n",
    "print(\"after get_info\")\n",
    "\n",
    "# Brief\n",
    "briefs <- data$项目简介\n",
    "data$BInfo <- get_info(briefs)\n",
    "\n",
    "print(\"after get_info\")\n",
    "# Detail\n",
    "detail_result <- process_detail(data$`项目介绍`)\n",
    "print(\"after process_detail\")\n",
    "\n",
    "data$photo <- detail_result$photo\n",
    "details <- detail_result$details\n",
    "\n",
    "data$DInfo <- get_info(details)\n",
    "print(\"after detail\")\n",
    "marks <- get_mark(details)\n",
    "data$Exclamation <- marks$Exclamation\n",
    "data$QMark <- marks$QMark\n",
    "print(\"at last\")\n",
    "# 打印数据框的所有列的标签\n",
    "print(colnames(data))\n",
    "write_csv(data, \"precessed_need_python.csv\")\n",
    "document_frequency <- document_frequency(details)\n",
    "# 这里有问题\n",
    "data$entropy <- sapply(details, calculate_entropy)\n",
    "\n",
    "\n",
    "print(\"here\")\n",
    "print(data)\n",
    "# 数据存到新的csv里面\n",
    "write_csv(data, \"precessed_need_python.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
